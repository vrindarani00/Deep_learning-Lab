{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2480d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/4,step100/600,loss = 16.0581\n",
      "epoch 1/4,step200/600,loss = 15.2976\n",
      "epoch 1/4,step300/600,loss = 14.5445\n",
      "epoch 1/4,step400/600,loss = 13.8048\n",
      "epoch 1/4,step500/600,loss = 13.1180\n",
      "epoch 1/4,step600/600,loss = 12.4373\n",
      "epoch 2/4,step100/600,loss = 11.7680\n",
      "epoch 2/4,step200/600,loss = 11.1408\n",
      "epoch 2/4,step300/600,loss = 10.5267\n",
      "epoch 2/4,step400/600,loss = 9.9422\n",
      "epoch 2/4,step500/600,loss = 9.3787\n",
      "epoch 2/4,step600/600,loss = 8.8135\n",
      "epoch 3/4,step100/600,loss = 8.3079\n",
      "epoch 3/4,step200/600,loss = 7.8320\n",
      "epoch 3/4,step300/600,loss = 7.3388\n",
      "epoch 3/4,step400/600,loss = 6.9067\n",
      "epoch 3/4,step500/600,loss = 6.4712\n",
      "epoch 3/4,step600/600,loss = 6.0714\n",
      "epoch 4/4,step100/600,loss = 5.6838\n",
      "epoch 4/4,step200/600,loss = 5.3520\n",
      "epoch 4/4,step300/600,loss = 5.0215\n",
      "epoch 4/4,step400/600,loss = 4.6964\n",
      "epoch 4/4,step500/600,loss = 4.4141\n",
      "epoch 4/4,step600/600,loss = 4.1659\n",
      "accuracy=63.16\n"
     ]
    }
   ],
   "source": [
    "#L1 NORM\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchvision #for datasets\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 784 #28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 4\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "#MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform = transforms.ToTensor(),download=True)\n",
    "#MNIST\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform = transforms.ToTensor(),download=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n",
    "class neuralnets(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(neuralnets,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size,num_classes)\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        return out\n",
    "model = neuralnets(input_size,hidden_size,num_classes).to(device)\n",
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "def L1(neuralnets, lamda=1e-2):\n",
    "    l1 = 0\n",
    "    for params in neuralnets.parameters():\n",
    "        l1 = l1 + params.abs().sum()\n",
    "    return lamda * l1\n",
    "n_total_steps = len(train_loader ) \n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        #100,1,28,28\n",
    "        #100,784\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels) + L1(model)\n",
    "\n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) %100 ==0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs},step{i+1}/{n_total_steps},loss = {loss.item():.4f}')\n",
    "#test\n",
    "with torch.no_grad():\n",
    "    n_correct =0\n",
    "    n_samples =0\n",
    "    for images ,labels in test_loader:\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        #value,index\n",
    "        _,predictions = torch.max(outputs,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "acc = 100.0*n_correct /n_samples\n",
    "print(f'accuracy={acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0561e9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/4,step100/600,loss = 2.2978\n",
      "epoch 1/4,step200/600,loss = 2.2887\n",
      "epoch 1/4,step300/600,loss = 2.2547\n",
      "epoch 1/4,step400/600,loss = 2.2617\n",
      "epoch 1/4,step500/600,loss = 2.2334\n",
      "epoch 1/4,step600/600,loss = 2.2151\n",
      "epoch 2/4,step100/600,loss = 2.1937\n",
      "epoch 2/4,step200/600,loss = 2.1790\n",
      "epoch 2/4,step300/600,loss = 2.1435\n",
      "epoch 2/4,step400/600,loss = 2.1177\n",
      "epoch 2/4,step500/600,loss = 2.1062\n",
      "epoch 2/4,step600/600,loss = 2.1080\n",
      "epoch 3/4,step100/600,loss = 2.0826\n",
      "epoch 3/4,step200/600,loss = 2.0021\n",
      "epoch 3/4,step300/600,loss = 2.0161\n",
      "epoch 3/4,step400/600,loss = 1.9869\n",
      "epoch 3/4,step500/600,loss = 1.9799\n",
      "epoch 3/4,step600/600,loss = 1.9666\n",
      "epoch 4/4,step100/600,loss = 1.8970\n",
      "epoch 4/4,step200/600,loss = 1.8841\n",
      "epoch 4/4,step300/600,loss = 1.8614\n",
      "epoch 4/4,step400/600,loss = 1.8836\n",
      "epoch 4/4,step500/600,loss = 1.7970\n",
      "epoch 4/4,step600/600,loss = 1.6988\n",
      "accuracy=73.18\n"
     ]
    }
   ],
   "source": [
    "#L2 NORM\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchvision #for datasets\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 784 #28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 4\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "#MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform = transforms.ToTensor(),download=True)\n",
    "#MNISTdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform = transforms.ToTensor(),download=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n",
    "class neuralnets(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(neuralnets,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size,num_classes)\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        return out\n",
    "model = neuralnets(input_size,hidden_size,num_classes).to(device)\n",
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "\n",
    "#training_loop\n",
    "n_total_steps = len(train_loader ) \n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        #100,1,28,28\n",
    "        #100,784\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) %100 ==0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs},step{i+1}/{n_total_steps},loss = {loss.item():.4f}')\n",
    "            \n",
    "         \n",
    "        \n",
    "    #test\n",
    "with torch.no_grad():\n",
    "    n_correct =0\n",
    "    n_samples =0\n",
    "    for images ,labels in test_loader:\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        #value,index\n",
    "        _,predictions = torch.max(outputs,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "acc = 100.0*n_correct /n_samples\n",
    "print(f'accuracy={acc}')\n",
    "         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4135be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/4,step100/600,loss = 2.2843\n",
      "epoch 1/4,step200/600,loss = 2.2846\n",
      "epoch 1/4,step300/600,loss = 2.2573\n",
      "epoch 1/4,step400/600,loss = 2.2492\n",
      "epoch 1/4,step500/600,loss = 2.2350\n",
      "epoch 1/4,step600/600,loss = 2.2165\n",
      "epoch 2/4,step100/600,loss = 2.1872\n",
      "epoch 2/4,step200/600,loss = 2.1866\n",
      "epoch 2/4,step300/600,loss = 2.1381\n",
      "epoch 2/4,step400/600,loss = 2.1120\n",
      "epoch 2/4,step500/600,loss = 2.0967\n",
      "epoch 2/4,step600/600,loss = 2.0955\n",
      "epoch 3/4,step100/600,loss = 2.0828\n",
      "epoch 3/4,step200/600,loss = 2.0839\n",
      "epoch 3/4,step300/600,loss = 2.0082\n",
      "epoch 3/4,step400/600,loss = 2.0310\n",
      "epoch 3/4,step500/600,loss = 1.9988\n",
      "epoch 3/4,step600/600,loss = 1.9828\n",
      "epoch 4/4,step100/600,loss = 1.9545\n",
      "epoch 4/4,step200/600,loss = 1.9271\n",
      "epoch 4/4,step300/600,loss = 1.8627\n",
      "epoch 4/4,step400/600,loss = 1.8246\n",
      "epoch 4/4,step500/600,loss = 1.7702\n",
      "epoch 4/4,step600/600,loss = 1.8017\n",
      "accuracy=57.83\n"
     ]
    }
   ],
   "source": [
    "#DROPOUT\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchvision #for datasets\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 784 #28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 4\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "#MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform = transforms.ToTensor(),download=True)\n",
    "#MNISTdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform = transforms.ToTensor(),download=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n",
    "class neuralnets(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes,dropout_prob=0.5):\n",
    "        super(neuralnets,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.l2 = nn.Linear(hidden_size,num_classes)\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out=self.l2(out)\n",
    "        return out\n",
    "model = neuralnets(input_size,hidden_size,num_classes).to(device)\n",
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "#training_loop\n",
    "n_total_steps = len(train_loader ) \n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        #100,1,28,28\n",
    "        #100,784\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) %100 ==0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs},step{i+1}/{n_total_steps},loss = {loss.item():.4f}')\n",
    "            \n",
    "   #test\n",
    "with torch.no_grad():\n",
    "    n_correct =0\n",
    "    n_samples =0\n",
    "    for images ,labels in test_loader:\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        #value,index\n",
    "        _,predictions = torch.max(outputs,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "acc = 100.0*n_correct /n_samples\n",
    "print(f'accuracy={acc}')      \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f016d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/4], Step [1000/12500], Loss: 2.2410\n",
      "Epoch [1/4], Step [2000/12500], Loss: 2.1764\n",
      "Epoch [1/4], Step [3000/12500], Loss: 2.2332\n",
      "Epoch [1/4], Step [4000/12500], Loss: 1.7825\n",
      "Epoch [1/4], Step [5000/12500], Loss: 1.5737\n",
      "Epoch [1/4], Step [6000/12500], Loss: 2.2624\n",
      "Epoch [1/4], Step [7000/12500], Loss: 1.7566\n",
      "Epoch [1/4], Step [8000/12500], Loss: 2.6342\n",
      "Epoch [1/4], Step [9000/12500], Loss: 1.4490\n",
      "Epoch [1/4], Step [10000/12500], Loss: 0.7092\n",
      "Epoch [1/4], Step [11000/12500], Loss: 1.9538\n",
      "Epoch [1/4], Step [12000/12500], Loss: 1.4541\n",
      "Epoch [2/4], Step [1000/12500], Loss: 2.0317\n",
      "Epoch [2/4], Step [2000/12500], Loss: 1.6994\n",
      "Epoch [2/4], Step [3000/12500], Loss: 1.6071\n",
      "Epoch [2/4], Step [4000/12500], Loss: 1.3699\n",
      "Epoch [2/4], Step [5000/12500], Loss: 1.1803\n",
      "Epoch [2/4], Step [6000/12500], Loss: 1.7728\n",
      "Epoch [2/4], Step [7000/12500], Loss: 1.6449\n",
      "Epoch [2/4], Step [8000/12500], Loss: 1.5095\n",
      "Epoch [2/4], Step [9000/12500], Loss: 1.5925\n",
      "Epoch [2/4], Step [10000/12500], Loss: 1.5347\n",
      "Epoch [2/4], Step [11000/12500], Loss: 1.2402\n",
      "Epoch [2/4], Step [12000/12500], Loss: 1.4702\n",
      "Epoch [3/4], Step [1000/12500], Loss: 0.8444\n",
      "Epoch [3/4], Step [2000/12500], Loss: 0.7346\n",
      "Epoch [3/4], Step [3000/12500], Loss: 1.0957\n",
      "Epoch [3/4], Step [4000/12500], Loss: 1.4826\n",
      "Epoch [3/4], Step [5000/12500], Loss: 1.4234\n",
      "Epoch [3/4], Step [6000/12500], Loss: 1.6232\n",
      "Epoch [3/4], Step [7000/12500], Loss: 2.1554\n",
      "Epoch [3/4], Step [8000/12500], Loss: 1.0215\n",
      "Epoch [3/4], Step [9000/12500], Loss: 0.9246\n",
      "Epoch [3/4], Step [10000/12500], Loss: 1.0965\n",
      "Epoch [3/4], Step [11000/12500], Loss: 1.6744\n",
      "Epoch [3/4], Step [12000/12500], Loss: 1.0109\n",
      "Epoch [4/4], Step [1000/12500], Loss: 1.9872\n",
      "Epoch [4/4], Step [2000/12500], Loss: 1.5526\n",
      "Epoch [4/4], Step [3000/12500], Loss: 1.3956\n",
      "Epoch [4/4], Step [4000/12500], Loss: 1.1605\n",
      "Epoch [4/4], Step [5000/12500], Loss: 1.0021\n",
      "Epoch [4/4], Step [6000/12500], Loss: 0.5139\n",
      "Epoch [4/4], Step [7000/12500], Loss: 1.4760\n",
      "Epoch [4/4], Step [8000/12500], Loss: 0.4616\n",
      "Epoch [4/4], Step [9000/12500], Loss: 1.2814\n",
      "Epoch [4/4], Step [10000/12500], Loss: 0.8348\n",
      "Epoch [4/4], Step [11000/12500], Loss: 1.1138\n",
      "Epoch [4/4], Step [12000/12500], Loss: 0.2963\n",
      "Accuracy of the model on the test images: 55.39%\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Load the CIFAR10 dataset and apply transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy of the model on the test images: {accuracy}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d21648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Iteration: 500. Loss: 2.2987639904022217. Accuracy: 17.709999084472656\n",
      "Iteration: 1000. Loss: 2.2869951725006104. Accuracy: 12.579999923706055\n",
      "Iteration: 1500. Loss: 2.272036552429199. Accuracy: 17.3700008392334\n",
      "Iteration: 2000. Loss: 2.032484531402588. Accuracy: 30.040000915527344\n",
      "Iteration: 2500. Loss: 1.097590684890747. Accuracy: 63.27000045776367\n",
      "Iteration: 3000. Loss: 0.6638249754905701. Accuracy: 75.4800033569336\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
    "        # This is part of truncated backpropagation through time (BPTT)\n",
    "        out, hn = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# JUST PRINTING MODEL & PARAMETERS \n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "seq_dim = 28  \n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        # Load images as tensors with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            model.eval()\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Resize images\n",
    "                images = images.view(-1, seq_dim, input_dim)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86acbbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Iteration: 500. Loss: 2.2825891971588135. Accuracy: 18.299999237060547\n",
      "Iteration: 1000. Loss: 1.991916298866272. Accuracy: 57.279998779296875\n",
      "Iteration: 1500. Loss: 0.5215937495231628. Accuracy: 84.29000091552734\n",
      "Iteration: 2000. Loss: 0.34819865226745605. Accuracy: 92.45999908447266\n",
      "Iteration: 2500. Loss: 0.203627809882164. Accuracy: 93.62999725341797\n",
      "Iteration: 3000. Loss: 0.3045560121536255. Accuracy: 95.87999725341797\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # 28 time steps\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "len(list(model.parameters()))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "# Number of steps to unroll\n",
    "seq_dim = 28  \n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as a torch tensor with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Resize images\n",
    "                images = images.view(-1, seq_dim, input_dim)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2a9186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.6659\n",
      "Epoch [1/5], Step [200/600], Loss: 0.3463\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2485\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1720\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1476\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1215\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0579\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0587\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0957\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0356\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1853\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0702\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0916\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0305\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0862\n",
      "Epoch [3/5], Step [400/600], Loss: 0.1062\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0115\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0130\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0261\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1130\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0300\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0477\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0192\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0333\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0094\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0178\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0068\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0787\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0250\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0081\n",
      "Test Accuracy: 98.50%\n"
     ]
    }
   ],
   "source": [
    "#GRU\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# RNN (GRU) model\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model = GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5687e984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/469], Loss: 0.6881\n",
      "Epoch [1/10], Step [200/469], Loss: 0.5554\n",
      "Epoch [1/10], Step [300/469], Loss: 0.5307\n",
      "Epoch [1/10], Step [400/469], Loss: 0.5085\n",
      "Epoch [2/10], Step [100/469], Loss: 0.4844\n",
      "Epoch [2/10], Step [200/469], Loss: 0.4840\n",
      "Epoch [2/10], Step [300/469], Loss: 0.5020\n",
      "Epoch [2/10], Step [400/469], Loss: 0.4751\n",
      "Epoch [3/10], Step [100/469], Loss: 0.4772\n",
      "Epoch [3/10], Step [200/469], Loss: 0.4870\n",
      "Epoch [3/10], Step [300/469], Loss: 0.4956\n",
      "Epoch [3/10], Step [400/469], Loss: 0.4818\n",
      "Epoch [4/10], Step [100/469], Loss: 0.5024\n",
      "Epoch [4/10], Step [200/469], Loss: 0.4797\n",
      "Epoch [4/10], Step [300/469], Loss: 0.4741\n",
      "Epoch [4/10], Step [400/469], Loss: 0.4937\n",
      "Epoch [5/10], Step [100/469], Loss: 0.4683\n",
      "Epoch [5/10], Step [200/469], Loss: 0.4813\n",
      "Epoch [5/10], Step [300/469], Loss: 0.4569\n",
      "Epoch [5/10], Step [400/469], Loss: 0.4615\n",
      "Epoch [6/10], Step [100/469], Loss: 0.4704\n",
      "Epoch [6/10], Step [200/469], Loss: 0.4837\n",
      "Epoch [6/10], Step [300/469], Loss: 0.4789\n",
      "Epoch [6/10], Step [400/469], Loss: 0.4736\n",
      "Epoch [7/10], Step [100/469], Loss: 0.4574\n",
      "Epoch [7/10], Step [200/469], Loss: 0.4839\n",
      "Epoch [7/10], Step [300/469], Loss: 0.4686\n",
      "Epoch [7/10], Step [400/469], Loss: 0.4773\n",
      "Epoch [8/10], Step [100/469], Loss: 0.4793\n",
      "Epoch [8/10], Step [200/469], Loss: 0.4751\n",
      "Epoch [8/10], Step [300/469], Loss: 0.4593\n",
      "Epoch [8/10], Step [400/469], Loss: 0.4969\n",
      "Epoch [9/10], Step [100/469], Loss: 0.4790\n",
      "Epoch [9/10], Step [200/469], Loss: 0.4844\n",
      "Epoch [9/10], Step [300/469], Loss: 0.4628\n",
      "Epoch [9/10], Step [400/469], Loss: 0.4851\n",
      "Epoch [10/10], Step [100/469], Loss: 0.4825\n",
      "Epoch [10/10], Step [200/469], Loss: 0.4723\n",
      "Epoch [10/10], Step [300/469], Loss: 0.4607\n",
      "Epoch [10/10], Step [400/469], Loss: 0.4743\n"
     ]
    }
   ],
   "source": [
    "#AUTOENCODER\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4, 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Initialize the autoencoder model\n",
    "model = Autoencoder().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267c372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
